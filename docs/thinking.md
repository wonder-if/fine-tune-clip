# 对 CLIP 适应下游任务的一些思考

## 1. 适应而非微调

CLIP 模型能够在无需任何微调的情况下对图像进行分类，这得益于：
- CLIP 能够利用类别名称作为图像的标签，而非one-hot编码。
- CLIP 的训练数据中包含大量的类别名称，使得模型能够学习到类别名称和图像之间的关联。

但是，这种适应能力并不是完美的, CLIP 在很多数据集上的zero-shot能力还不能完全令人满意，而我们试图采用一些额外的技巧来提升 CLIP 的适应能力。

“微调”一词，在机器学习领域通常指的是在预训练模型的基础上，针对特定任务进行更加轻量地训练，以提升模型在该任务上的性能。大概有以下几种方式：
- fine-tune，即对整个模型进行训练，包括所有的参数。
- layer-wise fine-tune，即只训练模型的一部分，例如只训练最后几层。
- linear probe，即只训练最后一层全连接层，或是额外加一层全连接层用于训练。
- adapter，即通过在模型中添加额外的模块，例如adapter layer，来提升模型的适应能力。
- prompt，即通过在输入数据中添加一些额外的信息，例如提示词，来引导模型生成更好的输出。

“适应”相对于“微调”来说，具有更广的含义，所有能够提升模型在新任务、新场景、新数据集的技巧，都可以被称为“适应”。其除了微调以外，还可以包括推理阶段的增强方法（后处理），例如：标签传播、图结构推理、记忆检索、伪标记子训练等。

## 2. 我们专注于什么



